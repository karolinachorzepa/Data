{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AUM Lab 1.1 Regresja Notebook with R 14/11/21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karolinachorzepa/Dataanalysis_pandas_plotly_matplotlib_numpy/blob/master/AUM_Lab_1_1_Regresja_Notebook_with_R_14_11_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWi_-wW7SSa"
      },
      "source": [
        "# **LAB 1.1 Algorytmy Uczenia Maszynowego**\n",
        "v2021\n",
        "## **Uczenie nadzorowane - regresja**\n",
        "###Celem tego laboratorium jest:\n",
        "- Praktyczne zapoznanie się z elementami modelu regresji oraz wpływem hiperparametrów na wynik szacunku parametrów.  \n",
        "- Zdobycie umiejętności dopasowania linii regresji do danych i oceny modelu regresji w R\n",
        "- Ogólne zaznajomnienie z jezykiem R w środowisku notatników Jupyter, które popularnie jest wykorzystywane w porotypowaniu i analityce Data Science.\n",
        "\n",
        "###Plan:\n",
        "- Instalacja i wczytanie potrzebnych bibliotek oraz danych\n",
        "- Wstępne zapoznanie się z danymi oraz sformułowanie problemu\n",
        "- Szacowanie parametrów modelu: spadek gradientowy, hiperparametry\n",
        "- Predykcja i ewaluacja modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP7pfZEjvEXN"
      },
      "source": [
        "### **Intro**\n",
        "Skopiuj notebook! **File > Save a copy in Drive**\n",
        "\n",
        "You can have a simply empty R jupyter notebook in colab by using this URL link\n",
        "https://colab.research.google.com/#create=true&language=r\n",
        "\n",
        "Useful recap: https://www.roelpeters.be/running-an-r-kernel-in-google-colab/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMq82jig6hfa"
      },
      "source": [
        "# Sprawdź wersję R\n",
        "R.version.string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl6voa3g5R6R"
      },
      "source": [
        "text <- 'Hello, world!'\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cydzVqRbowqm"
      },
      "source": [
        "# Zainstaluj potrzebne pakiety\n",
        "install.packages(\"caret\")\n",
        "install.packages(\"gridExtra\")\n",
        "install.packages(\"Metrics\")\n",
        "require(Metrics)\n",
        "library(caret)\n",
        "library(\"gridExtra\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoXAZVV57Ar_"
      },
      "source": [
        "# Sprawdź czy dany pakiet jest zainstalowany\n",
        "require('ggmap')\n",
        "require('ggplot2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXY7MaFOEkDc"
      },
      "source": [
        "Inicjujemy ziarno generatora liczb losowych, aby wyniki były odtwarzalne i za każdym razem takie same przy uruchomieniu skryptu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRBxe0zNEZwG"
      },
      "source": [
        "# Ziarno dla replikacji\n",
        "set.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WLn8wpU6oHZ"
      },
      "source": [
        "# **Uczenie nadzorowane**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhOllpkq_5ff"
      },
      "source": [
        "### Zbiór danych do użycia: Boston Housing \n",
        "\n",
        "Źródło:\n",
        "* Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. *J. Environ. Economics and Management* 5, 81–102.\n",
        "* Belsley D.A., Kuh, E. and Welsch, R.E. (1980) *Regression Diagnostics. Identifying Influential Data and Sources of Collinearity*. New York: Wiley.\n",
        "\n",
        "Dane dostępne publicznie w kilku miejscach: \n",
        "* Repozytorium danych [UCI](http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data) \n",
        "* W ramach pakietu R MASS (Boston Massachusetts)\n",
        "* Inne popularne strony dedykowane Data Science, np. [Kaggle](https://www.kaggle.com/c/boston-housing)\n",
        "\n",
        "**The Boston data frame zawiera 506 wierszy i 14 kolumn:**\n",
        "* crim - per capita crime rate by town.\n",
        "* zn - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "* indus - proportion of non-retail business acres per town.\n",
        "* chas - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
        "* nox - nitrogen oxides concentration (parts per 10 million).\n",
        "* rm - average number of rooms per dwelling.\n",
        "* age - proportion of owner-occupied units built prior to 1940.\n",
        "* dis - weighted mean of distances to five Boston employment centres.\n",
        "* rad - index of accessibility to radial highways.\n",
        "* tax - full-value property-tax rate per \\$10,000.\n",
        "* ptratio - pupil-teacher ratio by town.\n",
        "* black - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
        "* lstat - lower status of the population (percent).\n",
        "* medv - median value of owner-occupied homes in \\$1000s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAIs905v9DaE"
      },
      "source": [
        "# Wczytaj dane z repozytorium internetowego\n",
        "housing <- read.table(\"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\")\n",
        "print(head(housing))\n",
        "\n",
        "# Zmień/przypisz nazwy kolumn\n",
        "names(housing) <- c('crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat', 'medv')\n",
        "# Zobacz jak wyglądają dane, kilka wierszy od góry head() lub dołu tail()\n",
        "head(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNEk0Rgw46Ca"
      },
      "source": [
        "# Wczytaj dane z biblioteki R\n",
        "require(MASS)\n",
        "housing <- Boston\n",
        "\n",
        "names(housing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFebX6cKtgyp"
      },
      "source": [
        "#### **Problem: Czy można przewidzieć wartość domu w zależności od liczby pokoi?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "200suiIa9D9L"
      },
      "source": [
        "# Zobaczmy jak rozkładają się obserwacje w zbiorze danych\n",
        "plot(housing$rm,housing$medv, col='black', main='Liczba pokoi a wartość domów')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3726rf99EAP"
      },
      "source": [
        "# Histogram mediany wartości (medv)\n",
        "\n",
        "ggplot(housing, aes(x=medv)) + geom_histogram(color=\"black\", fill=\"white\",aes(y=..density..), position=\"identity\", alpha=0.5) +\n",
        "geom_density(alpha=0.6) \n",
        "# + labs(x = \"medv\", y = \"Gęstość\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzxJ_i5I9ECv"
      },
      "source": [
        "# hist(housing$rm)\n",
        "ggplot(housing, aes(x=rm)) + geom_histogram(color=\"black\", fill=\"white\",aes(y=..density..), position=\"identity\", alpha=0.5) +\n",
        "geom_density(alpha=0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTCHWRn4WUdj"
      },
      "source": [
        "#---------------------------------------------------------\n",
        "#Zbiór treningowy, walidacyjny i testowy: losowanie próbek\n",
        "#---------------------------------------------------------\n",
        "set.seed(1234)\n",
        "# Losowanie z zastępowaniem. \n",
        "# Można też użyć createDataPartition() z biblioteki caret\n",
        "index <- sample(3, nrow(housing), replace=TRUE, prob=c(0.6, 0.2, 0.2))\n",
        "#head(ind)\n",
        "\n",
        "# Compose training set\n",
        "housing.train <- housing[index==1, 1:14]\n",
        "# Compose validation set\n",
        "housing.val <- housing[index==2, 1:14]\n",
        "# Compose test set\n",
        "housing.test <- housing[index==3, 1:14]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v44_MbdpMqxe"
      },
      "source": [
        "# Sprawdzenie podziału procentowego\n",
        "prop.table(table(index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjRyq2b-M6Sm"
      },
      "source": [
        "hist(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xkbKo98tw_p"
      },
      "source": [
        "#------------------------------------------------------------------\n",
        "# Częstą praktyką jest również osobne zapisanie zmiennej zależnej y \n",
        "# oraz macierzy zmiennych niezależnych x\n",
        "#------------------------------------------------------------------\n",
        "\n",
        "#Zbiór treningowy\n",
        "y_train = housing.train$medv\n",
        "x_train <- housing.train$rm\n",
        "# Zbiór walidacyjny\n",
        "y_val = housing.val$medv\n",
        "x_val <- housing.val$rm\n",
        "# Zbiór testowy\n",
        "y_test = housing.test$medv\n",
        "x_test <- housing.test$rm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebW85crtXDpG"
      },
      "source": [
        "# Zobaczmy jak rozkładają się obserwacje w podzielonym zbiorze danych\n",
        "ggplot(housing, aes(x=rm, y=medv)) + geom_point() +  facet_wrap(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUunzEfMA1b9"
      },
      "source": [
        "### **1. Regresja liniowa - wstęp**\n",
        "\n",
        "Regresja liniowa zakłada liniową zależność pomiędzy zmiennymi objaśniającymi i objaśnianymi. Zakłada zetem, że zmiana w $y$ jest proporcjonalna do zmiany w $x_{i}$.\n",
        "\n",
        "$y = \\theta_{0} +  \\theta_{1}x_{1} + \\theta_{2}x_{2} + ...$\n",
        "\n",
        "Zadaniem regresji liniowej jest wyznaczenie parametrów $\\theta$ tak, aby hipoteza była jak najbliższa prawdziwej funkcji dla przykładów trenujących $(𝑥, y)$. \n",
        "\n",
        "Najprostszy przypadek: model z jednym atrybutem:\n",
        "\n",
        "$h(x|\\theta) = \\theta_{0} +  \\theta_{1}x_{1} + ϵ$\n",
        "\n",
        "#### **Problem: Czy można przewidzieć wartość domu w zależności od liczby pokoi?**\n",
        "\n",
        "$medv = \\theta_{0} +  \\theta_{1}rm + ϵ$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFruUWfmO-GM"
      },
      "source": [
        "### Budowanie i szacowanie parametrów modelu regresji na zbiorze treningowym:\n",
        "* I Analitycznie: z układu równań normalnych $θ=(X^{T}X)^{−1}  X^{T}y$\n",
        "* II Z pakietem R i dedykowaną funkcją: `lm()`\n",
        "\n",
        "* III Przy pomocy algorytmu spadku gradientowego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfhxQjG9Vi9J"
      },
      "source": [
        "### I Rozwiązanie analityczne, układ równań normalnych w zapisie wektorowym: \n",
        "\n",
        "$θ=(X^{T}X)^{−1}  X^{T}y$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkwZUBkiGsoA"
      },
      "source": [
        "# Rozwiązanie analityczne: θ=(XTX)−1XTy\n",
        "X <- cbind(1, matrix(x_train)) # Dodajemy kolumnę jedynek \n",
        "theta_a = solve((t(X)%*%X))%*%t(X)%*%y_train\n",
        "theta_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS3FEx0bURjk"
      },
      "source": [
        "### II Regresja liniowa w R: lm()\n",
        "Ogólna postać: `model <- lm(y_zmienna_wyjściowa ~ x_atrybut_1, zbiór_danych)` \n",
        "\n",
        "model: nazwa dowolna, często fit\n",
        "\n",
        "Formuła hipotezy dla jednego atrybutu: `y ~ x)` \n",
        "\n",
        "Formuła hipotezy dla wielu atrybutów: `y ~ x1 + x2 + x3`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cbZQE7yGsuq"
      },
      "source": [
        "# Regresja liniowa w R: dopasuj linię regresji \n",
        "fit <- lm( y_train ~ x_train ) \n",
        "\n",
        "# Pokaż strukturę modelu i oszacowane parametry\n",
        "fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-tGwCrxGsz6"
      },
      "source": [
        "# Same wartości oszacowancyh parametrów\n",
        "print(fit$coefficients)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcUcRTwIrEC6"
      },
      "source": [
        "# Wartość theta1 - indeks zaczyna się od 1!\n",
        "print(summary(fit)$coefficients[2,1]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-s4QUznGs82"
      },
      "source": [
        "# Inne atrybuty dopasowanego modelu do przeglądania\n",
        "print(attributes(fit))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZaWKQ1ZfNq-"
      },
      "source": [
        "# Zbiór treningowy z dopasowaną linią regresji\n",
        "plot(x_train,y_train, col=rgb(0.2,0.4,0.6,0.4), main='Dopasowana linia regresji')\n",
        "# Nadpisz linię regresji\n",
        "abline(fit, col='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jMqlSFDv_2E"
      },
      "source": [
        "### III Wyznaczanie parametrów regresji liniowej przy pomocy spadku gradientowego\n",
        "\n",
        "**Błąd średniokwadratowy, funkcja kosztu**\n",
        "\n",
        "![picture](https://3.bp.blogspot.com/-7vLgOxMhaBg/Tqjb34B9A9I/AAAAAAAADIg/w5E6cXN6x1c/s1600/cost_function.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZjSMp7hvnnD"
      },
      "source": [
        "# Funkcja kosztu: błąd średniokwadratowy\n",
        "cost <- function(X, y, theta) {\n",
        "    # Wymiary macierzy danych:\n",
        "    # X: m,len(theta)\n",
        "    # y: m*1\n",
        "    # theta: liczba parametrów*1\n",
        "  sum((X %*% theta - y)^2) / (2*length(y))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFTl1ShpekpO"
      },
      "source": [
        "**Hiperparametry** - to watrości które ustawiamy na początku i których wartość nie zmienia się w trakcie danego szacowania parametrów. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRcN3tPTdGDa"
      },
      "source": [
        "# Parametr szybkości uczenia - wielkość kroku\n",
        "alpha <- 0.01\n",
        "\n",
        "#Liczba iteracji: Ile kroków zejścia gradientowego?\n",
        "num_iters <- 10000\n",
        "\n",
        "# Inicjalizacja parametrów - przykładowo zera: h = 0 + 0*x \n",
        "theta <- matrix(c(0,0), nrow=2)\n",
        "\n",
        "#---------------------------------------------------------\n",
        "# Zachowanie historii uczenia\n",
        "cost_history <- double(num_iters)\n",
        "theta_history <- list(num_iters)\n",
        "theta0_history <- double(num_iters)\n",
        "theta1_history <- double(num_iters)\n",
        "\n",
        "# add a column of 1's for the intercept coefficient\n",
        "X <- cbind(1, matrix(x_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWLO0km0fKTJ"
      },
      "source": [
        "![picture](https://2.bp.blogspot.com/-AdV-O-MoZHE/TtLibFTaf9I/AAAAAAAAAVM/aOxUGP7zl98/s1600/gradient+descent+algorithm+OLS.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF4-7TfXdGGN"
      },
      "source": [
        "# Spadek gradientowy - szacowanie parametrów hipotezy medv = theta0 +theta1*rm\n",
        "for (i in 1:num_iters) {\n",
        "  error <- (X %*% theta - y_train)\n",
        "  delta <- t(X) %*% error / length(y_train)\n",
        "  theta <- theta - alpha * delta       # Aktualizacja wartości parametrów\n",
        "  cost_history[i] <- cost(X, y_train, theta)\n",
        "  theta_history[[i]] <- theta\n",
        "  theta0_history[i] <- theta[1,1]\n",
        "  theta1_history[i] <- theta[2,1]\n",
        "}\n",
        "\n",
        "print('Oszacowane wartości parametrów theta przy danych wartościach: alpha, zainicjalizowanej theta i liczbie iteracji:')\n",
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xFo27CLfRqB"
      },
      "source": [
        "### Jaka jest różnica z rozwiązaniem analitycznym?\n",
        "* Zanotuj obserwacje.\n",
        "* Jakie elementy mogły mieć na to wpływ i jak/w jakim stopniu?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfkYzeM9dGI8"
      },
      "source": [
        "# Dane i stopniowa konwergencja dopasowania\n",
        "plot(x_train,y_train, col=rgb(0.2,0.4,0.6,0.4), main='Regresja liniowa - zejście gradientowe i proces uczenia')\n",
        "for (i in 1:num_iters) {\n",
        "  abline(coef=theta_history[[i]], col=rgb(0.8,0,0,0.3))\n",
        "}\n",
        "\n",
        "# Linia regresji algorytmu zejścia gradientowego\n",
        "abline(coef=theta, col='magenta', lwd = 5) \n",
        "legend(\"topleft\", legend=c(\"Hipoteza\", \"Obserwacje\"), lty=c(1,0), pch=c(NA, 16), col=c(rgb(0.8,0,0,0.3), rgb(0.2,0.4,0.6,0.4)))\n",
        "\n",
        "# Linia regresji rozwiązania analitycznego (niebieska)\n",
        "abline(coef=theta_a, col='blue', lwd = 5) \n",
        "legend(\"topleft\", legend=c(\"Hipoteza\", \"Obserwacje\", \"Rozwiązanie analityczne\"), lty=c(1,0,1), pch=c(NA, 16, NA), col=c(rgb(0.8,0,0,0.3), rgb(0.2,0.4,0.6,0.4), 'blue'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRL8oKY5dGMG"
      },
      "source": [
        "# Szczegóły eksperymentu\n",
        "layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))\n",
        "plot(cost_history, type='o', col='red', lwd=2, main='Funkcja kosztu', ylab='Koszt', xlab='Liczba kroków (iteracji)', ylim = c(0,max(cost_history)))\n",
        "plot(theta0_history, type='o', col='blue', lwd=2, main='Theta 0', ylab='Wartość theta0', xlab='Liczba kroków (iteracji)')\n",
        "plot(theta1_history, type='o', col='blue', lwd=2, main='Theta 1', ylab='Wartość theta1', xlab='Liczba kroków (iteracji)')\n",
        "plot(theta1_history, cost_history, col='green', lwd=2, main='Konwergencja wartości Theta 1', ylab='Wartość kosztu', xlab='Wartość theta1', xlim = c(1,18), ylim = c(0,max(cost_history)))\n",
        "points(summary(fit)$coefficients[2,1], sum(summary(fit)$residuals^2)/(2*length(y_train)), pch=16, col='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzl0nitedGVN"
      },
      "source": [
        "# 3D Plot (Loss Function, m, c) \n",
        "m <- seq(summary(fit)$coefficients[2,1] - 100, summary(fit)$coefficients[2,1] + 100, length=1000)  #seq(-100, 100, 5)\n",
        "c <- seq(summary(fit)$coefficients[1,1] - 100, summary(fit)$coefficients[1,1] + 100, length=1000)  #seq(-100, 100, 5)\n",
        "Y2<-sum(y_train^2)\n",
        "X2<-sum(x_train^2)\n",
        "XY<-sum(x_train*y_train)\n",
        "X<-sum(x_train)\n",
        "Y<-sum(y_train)\n",
        "loss <- Y2+X2*m^2+c^2*length(y_train)+2*XY*m+2*Y*c-2*X*m*c\n",
        "  \n",
        "f <- function(m, c) {\n",
        "     Y2+X2*m^2+c^2*length(y_train)+2*XY*m+2*Y*c-2*X*m*c\n",
        "     }\n",
        "\n",
        "z <- outer(m, c, f)\n",
        "persp(m, c, z, phi = 30, theta = 30, col = \"yellow\", xlab = \"m (Slope of the Line)\", ylab = \"c (Intercept on the Y-axis)\", zlab = \"Loss Function\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOs5l2GYlH_y"
      },
      "source": [
        "# 2D Heat map (Loss Function, m, c) \n",
        "image(m,c,z,xlab = \"m (Slope of the Line)\",ylab = \"c (Intercept on the Y-axis)\",main=\"Loss Function Vs (m & c)\")\n",
        "par(new=TRUE)\n",
        "contour(m,c,z, xaxt='n', yaxt='n',lwd = 2)\n",
        "abline(h=1,col=\"blue\")\n",
        "abline(v=1,col=\"blue\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TFMM2rHlrTK"
      },
      "source": [
        "## **Ćwiczenie 1**\n",
        "\n",
        "a) Zmień wartości parametru alpha i zanotuj obserwacje (np. 0.02, 0.03, 0.04, 0.001, 0.1, etc.)\n",
        "\n",
        "b) Zmień liczbę iteracji i zanotuj obserwacje\n",
        "\n",
        "c) Zmień wartości początkowe parametrów theta i zanotuj obserwacje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "risRMTqMl24b"
      },
      "source": [
        "## **Ćwiczenie 2** \n",
        "Zaimplementuj regresję liniową dwóch lub więcej zmiennych i zanotuj obserwacje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE6UGkbemUJu"
      },
      "source": [
        "# **Predykcja i ocena modelu**\n",
        "\n",
        "* Wytrenowaliśmy model.\n",
        "* Można go teraz użyć do predykcji na nowych danych i jego ewaluacji.\n",
        "\n",
        "\n",
        "**Ocena modelu:**\n",
        "* in-sample error - widzieliśmy stopniowo malejący błąd na danych treningowych\n",
        "* out-of-sample error - czy nasz model dobrze generalizuje?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UDSEdUCtT6c"
      },
      "source": [
        "## **Miary oceny modelu regresji liniowej I (RMSE)**\n",
        "\n",
        "Czy wytrenowany model dobrze generalizuje?\n",
        "\n",
        "\n",
        "Once we have a model, we use a \"metric\" to evaluate how well the model works. A metric is quantifiable and gives us an objective measure of how well the model predicts on new data. For regression problems, we will focus on:\n",
        "$$RMSE = \\sqrt{\\frac{\\sum_{i=1}^{N}(Predicted_{i} - Actual_{i})^{2}}{N}}$$\n",
        "\n",
        "Funkcja `lm()` w R wykorzystuje RMSE jako metryki do minimalizacji.\n",
        "\n",
        "Unfortunately, it's common practice to calculate RMSE on the same data we used to fit the model. This typically leads to overly-optimistic estimates of model performance. This is also known as overfitting. A better approach is to use out-of-sample estimates of model performance. \n",
        "\n",
        "However, it's useful to start off by looking at in-sample error, so we can contrast it later with out-of-sample error on the same dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhaIrYD3vTgp"
      },
      "source": [
        "### In-sample - ewaluacja na całym zbiorze danych (treningowych) - explanatory modelling approach\n",
        "Praktycznie gwarantuje przeuczenie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh65ZYuCnlrr"
      },
      "source": [
        "# Fit lm model: model\n",
        "model <- lm(medv ~ rm, housing.train)\n",
        "\n",
        "# Predict on full data: p\n",
        "predictions <- predict(model, housing.train)\n",
        "\n",
        "# Compute errors: error\n",
        "error <- predictions - housing.train[[\"medv\"]]\n",
        "\n",
        "# Calculate RMSE\n",
        "sqrt(mean(error ^ 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EslHognhs12i"
      },
      "source": [
        "### Out-of-sample validation\n",
        "\n",
        "Teraz użyjemy danych walidacyjnych oraz modelu, który wytrenowaliśmy wcześniej na części danych w zbiorze treningowym (fit)\n",
        "\n",
        "`model <- lm(y_train ~ x_train, training_data)`\n",
        "\n",
        "aby uzyskać predykcje na nowych dancyh\n",
        "\n",
        "`p <- predict(model, new_data) `\n",
        "\n",
        "Focus here is on predictive modelling - cel to model który generalizuje dobrze na nowych danych. Key insight of machine learning. \n",
        "\n",
        "Pozwala na wybranie takiego modelu, który będzie dawał dobre wyniki w przyszłości na nowych danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SZPIP4flIC5"
      },
      "source": [
        "# Uwaga na nazwy zmiennych w modelu i nowej porcji danych predykcyjnych\n",
        "\n",
        "pred <- predict(model, newdata=housing.val)\n",
        "summary(pred)\n",
        "\n",
        "print(sqrt(mean((y_val-pred)^2))) # Błąd testowy (walidacyjny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiceN4TjlIF4"
      },
      "source": [
        "# Predictions plot versus data\n",
        "style <- c(rep(1,length(x_val)), rep(2,length(x_val)))\n",
        "plot(c(x_val, x_val),c(y_val, pred),  xaxt=\"n\", ylab=\"y_val and predicted\", xlab=\"x_val\", col=style, pch=1)\n",
        "abline(fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkWcejzdrRTu"
      },
      "source": [
        "# Biblioteka ggplot2\n",
        "# Zaznacz błędy\n",
        "df <- data.frame(x = x_val, y = c(pred, y_val), Grupa = rep(c(\"Model: Predykcje\", \"Obserwacje\"), each = length(x_val)))\n",
        "ggplot(df, aes(x=x, y=y, group = Grupa)) +\n",
        "  geom_point(aes(colour = Grupa), size = 3) + \n",
        "  geom_line(aes(group = x), linetype = 2) +\n",
        "  geom_abline(intercept = summary(fit)$coefficients[1,1], slope = summary(fit)$coefficients[2,1]) +\n",
        "  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),\n",
        "    panel.background = element_blank(), axis.line = element_line(colour = \"black\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK2VpnIStq2U"
      },
      "source": [
        "# Błąd średniokwadratowy: MSE\n",
        "print('Błąd treningowy średniokwadratowy: MSE')\n",
        "print(mean(fit$residuals^2))\n",
        "\n",
        "# RMSE (od ang. root mean square error) czyli średnia kwadratowa błędów (wariancja + obciążenie), który jest po prostu pierwiastkiem kwadratowym z MSE.\n",
        "print('Pierwiastek błędu średniokwadratowego: RMSE na zbiorze treningowym')\n",
        "print(sqrt(mean(fit$residuals^2))) # Błąd treningowy\n",
        "print('Pierwiastek błędu średniokwadratowego: RMSE na zbiorze walidacyjnym')\n",
        "print(sqrt(mean((y_val-pred)^2))) # Błąd testowy (walidacyjny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9CWK7TvnsO"
      },
      "source": [
        "### Walidacja krzyżowa (Cross-validation)\n",
        "\n",
        "W poprzednim pojejściu, ewaluacja miała miejce na nowych dancyh tylko raz. Jeden duży outlier może nam sporo zepsuć. Model performance is dependent on way the data is split. Not representative of the model’s ability to generalize.\n",
        "\n",
        " a better approach to validating models is to use multiple systematic test sets, rather than a single random train/test split. Solution: Cross-validation!\n",
        "\n",
        "Tutaj Obliczamy metryki na foldach, dzieląc zbiór na kilka train-test zborów i uśredniając out of sample error. Cel: bycie bardziej precyzyjnym. Każda obserwacja pojawia się tylko w jednym zbiorze testowym. \n",
        "\n",
        "Ale to podejście jest bardzo drogie! (Obliczeniowo)\n",
        "\n",
        "Pakiet `caret` umożliwia łatwą implementację walidacji krzyzowej. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkkkQYAmxHu8"
      },
      "source": [
        "set.seed(1234)\n",
        "\n",
        "# Fit liner regression model\n",
        "# model <- train(y ~ ., my_data)\n",
        "\n",
        "model <- train(\n",
        "  medv ~ rm, \n",
        "  housing.train,\n",
        "  method = \"lm\",\n",
        "  trControl = trainControl(\n",
        "    method = \"cv\", \n",
        "    number = 10,\n",
        "    verboseIter = TRUE\n",
        "  )\n",
        ")\n",
        "\n",
        "# Print model to console\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2buZHQ6zYvs"
      },
      "source": [
        "set.seed(1234)\n",
        "\n",
        "# You can do more than one iteration of cross validation! 5 x 5-fold cross-validation\n",
        "# method: repeatedcv\n",
        "\n",
        "# Fit lm model using 5 x 5-fold CV: model\n",
        "model <- train(\n",
        "  medv ~ rm, \n",
        "  housing.train,\n",
        "  method = \"lm\",\n",
        "  trControl = trainControl(\n",
        "    method = \"repeatedcv\", \n",
        "    number = 5,\n",
        "    repeats = 5, \n",
        "    verboseIter = TRUE\n",
        "  )\n",
        ")\n",
        "\n",
        "# Print model to console\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgsaDAQaz5RI"
      },
      "source": [
        "# Fianl evaluation on new test data!\n",
        "\n",
        "# Uwaga na nazwy zmiennych w modelu i nowej porcji danych predykcyjnych\n",
        "\n",
        "predtest <- predict(fit, newdata=data.frame(x_train=x_test))\n",
        "summary(predtest)\n",
        "\n",
        "print(sqrt(mean((y_test-predtest)^2))) # Błąd testowy (walidacyjny)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA8UWdmsPdtH"
      },
      "source": [
        "## **Miary oceny modelu regresji liniowej II $R^{2}$**\n",
        "* R-Squared is determined from the score method of the regression object.\n",
        "* For Regression, we are going to use the coefficient of determination as our way of evaluating the results, also referred to as R-Squared\n",
        "\n",
        "![picture](https://docs.oracle.com/cd/E12825_01/epm.111/cb_statistical/images/graphics/r_squared_constant.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLIH6E-vuetR"
      },
      "source": [
        "# Błąd testowy przy użyciu biblioteki\n",
        "print(rmse(y_val,pred)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er1PRkR-vMg3"
      },
      "source": [
        "# R-squared \n",
        "# Adjusted R-squared - corrects for the number of features\n",
        "summary(fit)$r.squared "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNbmagPJb2t2"
      },
      "source": [
        "### Podsumowanie modelu w R: `summary(nazwa_modelu)`\n",
        "Wyświetla szczegółowe informacje na temat dopasowania modelu i oszacowanych parametrów."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J95TmfgicCzs"
      },
      "source": [
        "summary(fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvSIF0khvqgq"
      },
      "source": [
        "#### **Interpretacja składowych podsumowania modelu regresji liniowej**\n",
        "\n",
        "![picture](https://www.ucl.ac.uk/~uctqiax/PUBLG100/2015/img/lm.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn_YrIKbsw38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVuDji7VvuSY"
      },
      "source": [
        "## **Założenia regresji (wybrane)**\n",
        "\n",
        "### Założenie: The regression model is linear in parameters\n",
        "### Założenie: The regression model is correctly specified"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxvpvu-vrRWk"
      },
      "source": [
        "# Założenie: Homoscedasticity of residuals or equal variance\n",
        "\n",
        "# Wizualna diagnostyka modelu\n",
        "#layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))\n",
        "par(mfrow=c(2,2)) \n",
        "plot(fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFuYn6SHrRZb"
      },
      "source": [
        "# Założenie: No perfect multicollinearity between explanatory variables\n",
        "\n",
        "# Variance Inflation factor (VIF). But, What is VIF?\n",
        "# VIF is a metric computed for every X variable that goes into a linear model. \n",
        "# If the VIF of a variable is high, it means the information in that variable is already explained by other X variables present in the given model, which means, more redundant is that variable. \n",
        "# So, lower the VIF (<2) the better. VIF for a X var is calculated as:\n",
        "#                         VIF=1/(1−Rsq)\n",
        "#vif(model)\n",
        "\n",
        "1/(1-summary(fit)$r.squared)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9vxvT4crRcD"
      },
      "source": [
        "# Założenie 10: Normality of residuals\n",
        "\n",
        "par(mfrow=c(2,2))\n",
        "plot(fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCG7dzVrirOl"
      },
      "source": [
        "# Podsumowanie\n",
        "W tym ćwiczeniu poznaliśmy zagadnienia związane z regresją liniową na przykładzie danych Boston housing. \n",
        "\n",
        "Zachęcam do przećwiczenia tych aspektów na innych zbiorach danych. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVEfoXniiuJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}